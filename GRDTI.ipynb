{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled4.ipynb","provenance":[],"authorship_tag":"ABX9TyP4thmo9a6JkJFrr4SE7meE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"AsEHYN2JUBvP","executionInfo":{"status":"ok","timestamp":1653097945423,"user_tz":-180,"elapsed":2252,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}}},"outputs":[],"source":["import numpy as np\n","import torch as th\n","import torch.nn as nn\n","import argparse\n","import easydict"]},{"cell_type":"code","source":["th.cuda.is_available()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aoCGgJL0ULOr","executionInfo":{"status":"ok","timestamp":1653097951232,"user_tz":-180,"elapsed":324,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"outputId":"3ccc901b-6009-460c-eb23-801cd30a7d7c"},"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":2}]},{"cell_type":"code","source":["#args = parser.parse_args(argv[1:])\n","\n","args = easydict.EasyDict({\n","     \"epochs\": 40,\n","     \"rounds\": 1,\n","     \"device\":\"cuda\",\n","     \"dim_embedding\":1000,\n","     \"k\":1,\n","     \"lr\":0.001,\n","     \"weight_decay\":0,\n","     \"reg_lambda\":1,\n","     \"patience\":6,\n","     \"alpha\":0.9,\n","     \"edge_drop\":0.5\n","})"],"metadata":{"id":"MtNMUk5ZURY-","executionInfo":{"status":"ok","timestamp":1653097965054,"user_tz":-180,"elapsed":299,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["def row_normalize(t):\n","    t = t.float()\n","    row_sums = t.sum(1) + 1e-12\n","    output = t / row_sums[:, None]\n","    output[th.isnan(output) | th.isinf(output)] = 0.0\n","    return output\n","\n","\n","def col_normalize(a_matrix, substract_self_loop):\n","    if substract_self_loop:\n","        np.fill_diagonal(a_matrix, 0)\n","    a_matrix = a_matrix.astype(float)\n","    col_sums = a_matrix.sum(axis=0) + 1e-12\n","    new_matrix = a_matrix / col_sums[np.newaxis, :]\n","    new_matrix[np.isnan(new_matrix) | np.isinf(new_matrix)] = 0.0\n","    return new_matrix\n","\n","\n","def l2_norm(t, axit=1):\n","    t = t.float()\n","    norm = th.norm(t, 2, axit, True) + 1e-12\n","    output = th.div(t, norm)\n","    output[th.isnan(output) | th.isinf(output)] = 0.0\n","    return output"],"metadata":{"id":"As7s-li2UUlf","executionInfo":{"status":"ok","timestamp":1653097979238,"user_tz":-180,"elapsed":303,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pip install dgl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zbThQtoNUUx_","executionInfo":{"status":"ok","timestamp":1653098015766,"user_tz":-180,"elapsed":4020,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"outputId":"fcb7a9ef-92b9-4ee2-d543-49c78e7e822c"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting dgl\n","  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 29.9 MB/s \n","\u001b[?25hRequirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n","Installing collected packages: dgl\n","Successfully installed dgl-0.6.1\n"]}]},{"cell_type":"code","source":["from torch import nn\n","from dgl import function as fn"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H4vJOAvQUffA","executionInfo":{"status":"ok","timestamp":1653098026764,"user_tz":-180,"elapsed":735,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"outputId":"6a23138f-2e5f-412c-f37c-507c8fec89a5"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Using backend: pytorch\n"]},{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]}]},{"cell_type":"code","source":["class Propagation(nn.Module):\n","    def __init__(self, k, alpha, edge_drop=0.):\n","        super(Propagation, self).__init__()\n","        self._k = k\n","        self._alpha = alpha\n","        self.edge_drop = nn.Dropout(edge_drop)\n","\n","    def forward(self, graph, feat):\n","        graph = graph.local_var().to('cuda')\n","        norm = th.pow(graph.in_degrees().float().clamp(min=1e-12), -0.5)\n","        shp = norm.shape + (1,) * (feat.dim() - 1)\n","        norm = th.reshape(norm, shp).to(feat.device)\n","        feat_0 = feat\n","        for _ in range(self._k):\n","            feat = feat * norm\n","            graph.ndata['h'] = feat\n","            #graph.edata['w'] = th.ones(graph.number_of_edges(), 1).to(feat.device)\n","            graph.edata['w'] = self.edge_drop(th.ones(graph.number_of_edges(), 1).to(feat.device))\n","            graph.update_all(fn.u_mul_e('h', 'w', 'm'), fn.sum('m', 'h'))\n","            feat = graph.ndata.pop('h')\n","            feat = feat * norm\n","            feat = (1 - self._alpha) * feat + self._alpha * feat_0\n","\n","        return feat"],"metadata":{"id":"TvjSo_tWUkFp","executionInfo":{"status":"ok","timestamp":1653098043509,"user_tz":-180,"elapsed":11,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["import dgl\n","import torch.nn.functional as F"],"metadata":{"id":"u5Xh37gaUkSX","executionInfo":{"status":"ok","timestamp":1653098054233,"user_tz":-180,"elapsed":19,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["class GRDTI(nn.Module):\n","    def __init__(self, g, n_disease, n_drug, n_protein, n_sideeffect, args):\n","        super(GRDTI, self).__init__()\n","        self.g = g\n","        self.device = th.device(args.device)\n","        self.dim_embedding = args.dim_embedding\n","\n","        self.activation = F.elu\n","        self.reg_lambda = args.reg_lambda\n","\n","        self.num_disease = n_disease\n","        self.num_drug = n_drug\n","        self.num_protein = n_protein\n","        self.num_sideeffect = n_sideeffect\n","\n","        self.drug_feat = nn.Parameter(th.FloatTensor(self.num_drug, self.dim_embedding))\n","        nn.init.normal_(self.drug_feat, mean=0, std=0.1)\n","        self.protein_feat = nn.Parameter(th.FloatTensor(self.num_protein, self.dim_embedding))\n","        nn.init.normal_(self.protein_feat, mean=0, std=0.1)\n","        self.disease_feat = nn.Parameter(th.FloatTensor(self.num_disease, self.dim_embedding))\n","        nn.init.normal_(self.disease_feat, mean=0, std=0.1)\n","        self.sideeffect_feat = nn.Parameter(th.FloatTensor(self.num_sideeffect, self.dim_embedding))\n","        nn.init.normal_(self.sideeffect_feat, mean=0, std=0.1)\n","\n","        # 邻居信息的权重矩阵，对应论文公式（1）中的Wr、br\n","        self.fc_DDI = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_D_ch = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_D_Di = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_D_Side = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_D_P = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_PPI = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_P_seq = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_P_Di = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_P_D = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_Di_D = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_Di_P = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","        self.fc_Side_D = nn.Linear(self.dim_embedding, self.dim_embedding).float()\n","\n","        self.propagation = Propagation(args.k, args.alpha, args.edge_drop)\n","\n","        # Linear transformation for reconstruction\n","        tmp = th.randn(self.dim_embedding).float()\n","        self.re_DDI = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_D_ch = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_D_Di = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_D_Side = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_D_P = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_PPI = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_P_seq = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        self.re_P_Di = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        #self.re_P_D = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        #self.re_Di_P = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        #self.re_Di_D = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","        #self.re_Side_D = nn.Parameter(th.diag(th.nn.init.normal_(tmp, mean=0, std=0.1)))\n","\n","        self.reset_parameters()\n","\n","    def reset_parameters(self):\n","        for m in GRDTI.modules(self):\n","            if isinstance(m, nn.Linear):\n","                nn.init.normal_(m.weight.data, mean=0, std=0.1)\n","                if m.bias is not None:\n","                    m.bias.data.fill_(0.1)\n","\n","    def forward(self, drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein,\n","                protein_sequence, protein_disease, drug_protein, drug_protein_mask):\n","\n","        disease_feat = th.mean(th.stack((th.mm(row_normalize(drug_disease.T).float(),\n","                                               F.relu(self.fc_Di_D(self.drug_feat))),\n","                                         th.mm(row_normalize(protein_disease.T).float(),\n","                                               F.relu(self.fc_Di_P(self.protein_feat))),\n","                                         self.disease_feat), dim=1), dim=1)\n","\n","        drug_feat = th.mean(th.stack((th.mm(row_normalize(drug_drug).float(),\n","                                            F.relu(self.fc_DDI(self.drug_feat))),\n","                                      th.mm(row_normalize(drug_chemical).float(),\n","                                            F.relu(self.fc_D_ch(self.drug_feat))),\n","                                      th.mm(row_normalize(drug_disease).float(),\n","                                            F.relu(self.fc_D_Di(self.disease_feat))),\n","                                      th.mm(row_normalize(drug_sideeffect).float(),\n","                                            F.relu(self.fc_D_Side(self.sideeffect_feat))),\n","                                      th.mm(row_normalize(drug_protein).float(),\n","                                            F.relu(self.fc_D_P(self.protein_feat))),\n","                                      self.drug_feat), dim=1), dim=1)\n","\n","        protein_feat = th.mean(th.stack((th.mm(row_normalize(protein_protein).float(),\n","                                               F.relu(self.fc_PPI(self.protein_feat))),\n","                                         th.mm(row_normalize(protein_sequence).float(),\n","                                               F.relu(self.fc_P_seq(self.protein_feat))),\n","                                         th.mm(row_normalize(protein_disease).float(),\n","                                               F.relu(self.fc_P_Di(self.disease_feat))),\n","                                         th.mm(row_normalize(drug_protein.T).float(),\n","                                               F.relu(self.fc_P_D(self.drug_feat))),\n","                                         self.protein_feat), dim=1), dim=1)\n","\n","        sideeffect_feat = th.mean(th.stack((th.mm(row_normalize(drug_sideeffect.T).float(),\n","                                                  F.relu(self.fc_Side_D(self.drug_feat))),\n","                                            self.sideeffect_feat), dim=1), dim=1)\n","\n","        node_feat = th.cat((disease_feat, drug_feat, protein_feat, sideeffect_feat), dim=0)\n","\n","        node_feat = self.propagation(dgl.to_homogeneous(self.g), node_feat)\n","\n","        disease_embedding = node_feat[:self.num_disease].to(self.device)\n","        drug_embedding = node_feat[self.num_disease:self.num_disease + self.num_drug].to(self.device)\n","        protein_embedding = node_feat[self.num_disease + self.num_drug:self.num_disease + self.num_drug +\n","                                                                       self.num_protein].to(self.device)\n","        sideeffect_embedding = node_feat[-self.num_sideeffect:].to(self.device)\n","\n","        disease_vector = l2_norm(disease_embedding)\n","        drug_vector = l2_norm(drug_embedding)\n","        protein_vector = l2_norm(protein_embedding)\n","        sideeffect_vector = l2_norm(sideeffect_embedding)\n","\n","        drug_drug_reconstruct = th.mm(th.mm(drug_vector, self.re_DDI), drug_vector.t())\n","        drug_drug_reconstruct_loss = th.sum(\n","            (drug_drug_reconstruct - drug_drug.float()) ** 2)\n","\n","        drug_chemical_reconstruct = th.mm(th.mm(drug_vector, self.re_D_ch), drug_vector.t())\n","        drug_chemical_reconstruct_loss = th.sum(\n","            (drug_chemical_reconstruct - drug_chemical.float()) ** 2)\n","\n","        drug_disease_reconstruct = th.mm(th.mm(drug_vector, self.re_D_Di), disease_vector.t())\n","        drug_disease_reconstruct_loss = th.sum(\n","            (drug_disease_reconstruct - drug_disease.float()) ** 2)\n","\n","        drug_sideeffect_reconstruct = th.mm(th.mm(drug_vector, self.re_D_Side), sideeffect_vector.t())\n","        drug_sideeffect_reconstruct_loss = th.sum(\n","            (drug_sideeffect_reconstruct - drug_sideeffect.float()) ** 2)\n","\n","        protein_protein_reconstruct = th.mm(th.mm(protein_vector, self.re_PPI), protein_vector.t())\n","        protein_protein_reconstruct_loss = th.sum(\n","            (protein_protein_reconstruct - protein_protein.float()) ** 2)\n","\n","        protein_sequence_reconstruct = th.mm(th.mm(protein_vector, self.re_P_seq), protein_vector.t())\n","        protein_sequence_reconstruct_loss = th.sum(\n","            (protein_sequence_reconstruct - protein_sequence.float()) ** 2)\n","\n","        protein_disease_reconstruct = th.mm(th.mm(protein_vector, self.re_P_Di), disease_vector.t())\n","        protein_disease_reconstruct_loss = th.sum(\n","            (protein_disease_reconstruct - protein_disease.float()) ** 2)\n","\n","        drug_protein_reconstruct = th.mm(th.mm(drug_vector, self.re_D_P), protein_vector.t())\n","        tmp = th.mul(drug_protein_mask.float(), (drug_protein_reconstruct - drug_protein.float()))\n","        DTI_potential = drug_protein_reconstruct - drug_protein.float()\n","        drug_protein_reconstruct_loss = th.sum(tmp ** 2)\n","\n","        other_loss = drug_drug_reconstruct_loss + drug_chemical_reconstruct_loss + drug_disease_reconstruct_loss + \\\n","                     drug_sideeffect_reconstruct_loss + protein_protein_reconstruct_loss + \\\n","                     protein_sequence_reconstruct_loss + protein_disease_reconstruct_loss\n","\n","        L2_loss = 0.\n","        for name, param in GRDTI.named_parameters(self):\n","            if 'bias' not in name:\n","                L2_loss = L2_loss + th.sum(param.pow(2))\n","        L2_loss = L2_loss * 0.5\n","\n","        tloss = drug_protein_reconstruct_loss + 1.0 * other_loss + self.reg_lambda * L2_loss\n","\n","        return tloss, drug_protein_reconstruct_loss, L2_loss, drug_protein_reconstruct, DTI_potential"],"metadata":{"id":"2ABGaiZVUomP","executionInfo":{"status":"ok","timestamp":1653098072178,"user_tz":-180,"elapsed":1170,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# -*- coding: utf-8 -*-\n","\n","import dgl\n","import time\n","import torch as th\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.metrics import roc_auc_score, roc_curve\n","from sklearn.metrics import average_precision_score, precision_recall_curve\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","\n","\n","def loda_data():\n","    network_path = '../data/'\n","\n","    drug_drug = np.loadtxt(network_path + 'mat_drug_drug.txt')\n","    true_drug = 708\n","    drug_chemical = np.loadtxt(network_path + 'Similarity_Matrix_Drugs.txt')\n","    drug_chemical = drug_chemical[:true_drug, :true_drug]\n","    drug_disease = np.loadtxt(network_path + 'mat_drug_disease.txt')\n","    drug_sideeffect = np.loadtxt(network_path + 'mat_drug_se.txt')\n","\n","    protein_protein = np.loadtxt(network_path + 'mat_protein_protein.txt')\n","    protein_sequence = np.loadtxt(network_path + 'Similarity_Matrix_Proteins.txt')\n","    protein_disease = np.loadtxt(network_path + 'mat_protein_disease.txt')\n","\n","    num_drug = len(drug_drug)\n","    num_protein = len(protein_protein)\n","\n","    # Removed the self-loop\n","    drug_chemical = drug_chemical - np.identity(num_drug)\n","    protein_sequence = protein_sequence / 100.\n","    protein_sequence = protein_sequence - np.identity(num_protein)\n","\n","    drug_protein = np.loadtxt(network_path + 'mat_drug_protein.txt')\n","\n","    # Removed DTIs with similar drugs or proteins\n","    #drug_protein = np.loadtxt(network_path + 'mat_drug_protein_homo_protein_drug.txt')\n","\n","    print(\"Load data finished.\")\n","\n","    return drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, protein_sequence, \\\n","           protein_disease, drug_protein\n","\n","\n","def ConstructGraph(drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, protein_sequence,\n","                   protein_disease, drug_protein):\n","    num_drug = len(drug_drug)\n","    num_protein = len(protein_protein)\n","    num_disease = len(drug_disease.T)\n","    num_sideeffect = len(drug_sideeffect.T)\n","\n","    list_drug = []\n","    for i in range(num_drug):\n","        list_drug.append((i, i))\n","\n","    list_protein = []\n","    for i in range(num_protein):\n","        list_protein.append((i, i))\n","\n","    list_disease = []\n","    for i in range(num_disease):\n","        list_disease.append((i, i))\n","\n","    list_sideeffect = []\n","    for i in range(num_sideeffect):\n","        list_sideeffect.append((i, i))\n","\n","    list_DDI = []\n","    for row in range(num_drug):\n","        for col in range(num_drug):\n","            if drug_drug[row, col] > 0:\n","                list_DDI.append((row, col))\n","\n","    list_PPI = []\n","    for row in range(num_protein):\n","        for col in range(num_protein):\n","            if protein_protein[row, col] > 0:\n","                list_PPI.append((row, col))\n","\n","    list_drug_protein = []\n","    list_protein_drug = []\n","    for row in range(num_drug):\n","        for col in range(num_protein):\n","            if drug_protein[row, col] > 0:\n","                list_drug_protein.append((row, col))\n","                list_protein_drug.append((col, row))\n","\n","    list_drug_sideeffect = []\n","    list_sideeffect_drug = []\n","    for row in range(num_drug):\n","        for col in range(num_sideeffect):\n","            if drug_sideeffect[row, col] > 0:\n","                list_drug_sideeffect.append((row, col))\n","                list_sideeffect_drug.append((col, row))\n","\n","    list_drug_disease = []\n","    list_disease_drug = []\n","    for row in range(num_drug):\n","        for col in range(num_disease):\n","            if drug_disease[row, col] > 0:\n","                list_drug_disease.append((row, col))\n","                list_disease_drug.append((col, row))\n","\n","    list_protein_disease = []\n","    list_disease_protein = []\n","    for row in range(num_protein):\n","        for col in range(num_disease):\n","            if protein_disease[row, col] > 0:\n","                list_protein_disease.append((row, col))\n","                list_disease_protein.append((col, row))\n","\n","    g_HIN = dgl.heterograph({('disease', 'disease_disease virtual', 'disease'): list_disease,\n","                             ('drug', 'drug_drug virtual', 'drug'): list_drug,\n","                             ('protein', 'protein_protein virtual', 'protein'): list_protein,\n","                             ('sideeffect', 'sideeffect_sideeffect virtual', 'sideeffect'): list_sideeffect,\n","                             ('drug', 'drug_drug interaction', 'drug'): list_DDI, \\\n","                             ('protein', 'protein_protein interaction', 'protein'): list_PPI, \\\n","                             ('drug', 'drug_protein interaction', 'protein'): list_drug_protein, \\\n","                             ('protein', 'protein_drug interaction', 'drug'): list_protein_drug, \\\n","                             ('drug', 'drug_sideeffect association', 'sideeffect'): list_drug_sideeffect, \\\n","                             ('sideeffect', 'sideeffect_drug association', 'drug'): list_sideeffect_drug, \\\n","                             ('drug', 'drug_disease association', 'disease'): list_drug_disease, \\\n","                             ('disease', 'disease_drug association', 'drug'): list_disease_drug, \\\n","                             ('protein', 'protein_disease association', 'disease'): list_protein_disease, \\\n","                             ('disease', 'disease_protein association', 'protein'): list_disease_protein})\n","\n","    g = g_HIN.edge_type_subgraph(['drug_drug interaction', 'protein_protein interaction',\n","                                  'drug_protein interaction', 'protein_drug interaction',\n","                                  'drug_sideeffect association', 'sideeffect_drug association',\n","                                  'drug_disease association', 'disease_drug association',\n","                                  'protein_disease association', 'disease_protein association'\n","                                  ])\n","\n","    return g\n","\n","\n","def TrainAndEvaluate(DTItrain, DTIvalid, DTItest, args, drug_drug, drug_chemical, drug_disease,\n","                     drug_sideeffect, protein_protein, protein_sequence, protein_disease):\n","    device = th.device(args.device)\n","\n","    # Numbers of different nodes\n","    num_disease = len(drug_disease.T)\n","    num_drug = len(drug_drug)\n","    num_protein = len(protein_protein)\n","    num_sideeffect = len(drug_sideeffect.T)\n","\n","    drug_protein = th.zeros((num_drug, num_protein))\n","    mask = th.zeros((num_drug, num_protein)).to(device)\n","    for ele in DTItrain:\n","        drug_protein[ele[0], ele[1]] = ele[2]\n","        mask[ele[0], ele[1]] = 1\n","\n","    best_valid_aupr = 0.\n","    # best_valid_auc = 0\n","    test_aupr = 0.\n","    test_auc = 0.\n","    patience = 0.\n","\n","    pos = np.count_nonzero(DTItest[:, 2])\n","    neg = np.size(DTItest[:, 2]) - pos\n","    xy_roc_sampling = []\n","    xy_pr_sampling = []\n","\n","    g = ConstructGraph(drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, protein_sequence,\n","                       protein_disease, drug_protein)\n","\n","    drug_drug = th.tensor(drug_drug).to(device)\n","    drug_chemical = th.tensor(drug_chemical).to(device)\n","    drug_disease = th.tensor(drug_disease).to(device)\n","    drug_sideeffect = th.tensor(drug_sideeffect).to(device)\n","    protein_protein = th.tensor(protein_protein).to(device)\n","    protein_sequence = th.tensor(protein_sequence).to(device)\n","    protein_disease = th.tensor(protein_disease).to(device)\n","    drug_protein = drug_protein.to(device)\n","\n","    model = GRDTI(g, num_disease, num_drug, num_protein, num_sideeffect, args)\n","    model.to(device)\n","\n","    optimizer = th.optim.Adam(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n","\n","    for i in range(args.epochs):\n","\n","        model.train()\n","        tloss, dtiloss, l2loss, dp_re, DTI_p = model(drug_drug, drug_chemical, drug_disease, drug_sideeffect,\n","                                                     protein_protein, protein_sequence, protein_disease,\n","                                                     drug_protein, mask)\n","\n","        results = dp_re.detach().cpu()\n","        optimizer.zero_grad()\n","        loss = tloss\n","        loss.backward()\n","        th.nn.utils.clip_grad_norm_(model.parameters(), 1)\n","        optimizer.step()\n","\n","        model.eval()\n","\n","        if i % 25 == 0:\n","            with th.no_grad():\n","                print(\"step\", i, \":\", \"Total_loss & DTIloss & L2_loss:\", loss.cpu().data.numpy(), \",\", dtiloss.item(),\n","                      \",\", l2loss.item())\n","\n","                pred_list = []\n","                ground_truth = []\n","\n","                for ele in DTIvalid:\n","                    pred_list.append(results[ele[0], ele[1]])\n","                    ground_truth.append(ele[2])\n","\n","                valid_auc = roc_auc_score(ground_truth, pred_list)\n","                valid_aupr = average_precision_score(ground_truth, pred_list)\n","\n","                if valid_aupr >= best_valid_aupr:\n","                    best_valid_aupr = valid_aupr\n","                    # best_valid_auc = valid_auc\n","                    best_DTI_potential = DTI_p\n","                    patience = 0\n","\n","                    # Calculating AUC & AUPR (pos:neg=1:10)\n","                    db = []\n","                    xy_roc = []\n","                    xy_pr = []\n","                    for ele in DTItest:\n","                        db.append([results[ele[0], ele[1]], ele[2]])\n","\n","                    db = sorted(db, key=lambda x: x[0], reverse=True)\n","\n","                    tp, fp = 0., 0.\n","                    for i_db in range(len(db)):\n","                        if db[i_db][0]:\n","                            if db[i_db][1]:\n","                                tp = tp + 1\n","                            else:\n","                                fp = fp + 1\n","                            xy_roc.append([fp / neg, tp / pos])\n","                            xy_pr.append([tp / pos, tp / (tp + fp)])\n","\n","                    test_auc = 0.\n","                    prev_x = 0.\n","                    for x, y in xy_roc:\n","                        if x != prev_x:\n","                            test_auc += (x - prev_x) * y\n","                            prev_x = x\n","\n","                    test_aupr = 0.\n","                    prev_x = 0.\n","                    for x, y in xy_pr:\n","                        if x != prev_x:\n","                            test_aupr += (x - prev_x) * y\n","                            prev_x = x\n","\n","                    # All unknown DTI pairs all treated as negative examples\n","                    '''pred_list = []\n","                    ground_truth = []\n","                    for ele in DTItest:\n","                        pred_list.append(results[ele[0], ele[1]])\n","                        ground_truth.append(ele[2])\n","                    test_auc = roc_auc_score(ground_truth, pred_list)\n","                    test_aupr = average_precision_score(ground_truth, pred_list)'''\n","\n","                else:\n","                    patience += 1\n","                    if patience > args.patience:\n","                        print(\"Early Stopping\")\n","\n","                        # sampling (pos:neg=1:10) for averaging and plotting\n","                        xy_roc_sampling = []\n","                        xy_pr_sampling = []\n","                        for i_xy in range(len(xy_roc)):\n","                            if i_xy % 10 == 0:\n","                                xy_roc_sampling.append(xy_roc[i_xy])\n","                                xy_pr_sampling.append(xy_pr[i_xy])\n","\n","                        # Record data for sampling, averaging and plotting.\n","                        # All unknown DTI pairs all treated as negative examples\n","                        '''t1 = time.localtime()\n","                        time_creat_txt = str(t1.tm_year) + '_' + str(t1.tm_mon) + '_' + str(t1.tm_mday) + '_' + str(\n","                            t1.tm_hour) + '_' + str(t1.tm_min)\n","                        fpr, tpr, threshold = roc_curve(ground_truth, pred_list)\n","                        print(\"len(fpr):\", len(fpr))\n","                        np.savetxt('fpr_' + time_creat_txt + '.csv', fpr)\n","                        np.savetxt('tpr_' + time_creat_txt + '.csv', tpr)\n","                        np.savetxt('ROC_threshold_' + time_creat_txt + '.csv', threshold)\n","\n","                        precision, recall, threshold = precision_recall_curve(ground_truth, pred_list)\n","                        print(\"len(recall):\", len(recall))\n","                        np.savetxt('precision_' + time_creat_txt + '.csv', precision)\n","                        np.savetxt('recall_' + time_creat_txt + '.csv', recall)\n","                        np.savetxt('PRC_threshold_' + time_creat_txt + '.csv', threshold)'''\n","\n","                        break\n","\n","                print('Valid auc & aupr:', valid_auc, valid_aupr, \";  \", 'Test auc & aupr:', test_auc, test_aupr)\n","                th.cuda.empty_cache()\n","           \n","    return test_auc, test_aupr, xy_roc_sampling, xy_pr_sampling, best_DTI_potential\n","    \n","\n","def main(args):\n","    drug_d, drug_ch, drug_di, drug_side, protein_p, protein_seq, protein_di, dti_original = loda_data()\n","\n","    # sampling\n","    whole_positive_index = []\n","    whole_negative_index = []\n","    for i in range(np.shape(dti_original)[0]):\n","        for j in range(np.shape(dti_original)[1]):\n","            if int(dti_original[i][j]) == 1:\n","                whole_positive_index.append([i, j])\n","            elif int(dti_original[i][j]) == 0:\n","                whole_negative_index.append([i, j])\n","\n","    # pos:neg=1:10\n","    negative_sample_index = np.random.choice(np.arange(len(whole_negative_index)),\n","                                             size=10 * len(whole_positive_index), replace=False)\n","\n","    # All unknown DTI pairs all treated as negative examples\n","    '''negative_sample_index = np.random.choice(np.arange(len(whole_negative_index)),\n","                                             size=len(whole_negative_index), replace=False)'''\n","\n","    data_set = np.zeros((len(negative_sample_index) + len(whole_positive_index), 3), dtype=int)\n","    count = 0\n","    for i in whole_positive_index:\n","        data_set[count][0] = i[0]\n","        data_set[count][1] = i[1]\n","        data_set[count][2] = 1\n","        count += 1\n","    for i in negative_sample_index:\n","        data_set[count][0] = whole_negative_index[i][0]\n","        data_set[count][1] = whole_negative_index[i][1]\n","        data_set[count][2] = 0\n","        count += 1\n","\n","    test_auc_round = []\n","    test_aupr_round = []\n","    tpr_mean = []\n","    fpr = []\n","    precision_mean = []\n","    recall = []\n","\n","    rounds = args.rounds\n","    for r in range(rounds):\n","        print(\"----------------------------------------\")\n","\n","        test_auc_fold = []\n","        test_aupr_fold = []\n","\n","        kf = StratifiedKFold(n_splits=10, random_state=None, shuffle=True)\n","        k_fold = 0\n","\n","        for train_index, test_index in kf.split(data_set[:, :2], data_set[:, 2]):\n","            train = data_set[train_index]\n","            DTItest = data_set[test_index]\n","            DTItrain, DTIvalid = train_test_split(train, test_size=0.05, random_state=None)\n","\n","            k_fold += 1\n","            print(\"--------------------------------------------------------------\")\n","            print(\"round \", r + 1, \" of \", rounds, \":\", \"KFold \", k_fold, \" of 10\")\n","            print(\"--------------------------------------------------------------\")\n","\n","            time_roundStart = time.time()\n","\n","            t_auc, t_aupr, xy_roc, xy_pr, DTI_potential = TrainAndEvaluate(DTItrain, DTIvalid, DTItest, args, drug_d,\n","                                                                           drug_ch, drug_di, drug_side, protein_p,\n","                                                                           protein_seq, protein_di)\n","\n","            time_roundEnd = time.time()\n","            print(\"Time spent in this fold:\", time_roundEnd - time_roundStart)\n","            test_auc_fold.append(t_auc)\n","            test_aupr_fold.append(t_aupr)\n","\n","            order_txt1 = 'DTI_potential_' + 'r' + str(r + 1) + '_f' + str(k_fold) + '.csv'\n","            np.savetxt(order_txt1, DTI_potential.detach().cpu().numpy(), fmt='%-.4f', delimiter=',')\n","            top_values, top_indices = th.topk(DTI_potential, 40)\n","            order_txt2 = 'top40_' + 'r' + str(r + 1) + '_f' + str(k_fold) + '.csv'\n","            np.savetxt(order_txt2, top_indices.detach().cpu().numpy(), fmt='%d', delimiter=',')\n","\n","            # pos:neg=1:10\n","            if not fpr:\n","                fpr = [_v[0] for _v in xy_roc]\n","            if not recall:\n","                recall = [_v[0] for _v in xy_pr]\n","\n","            temp = [_v[1] for _v in xy_roc]\n","            tpr_mean.append(temp)\n","            temp = [_v[1] for _v in xy_pr]\n","            precision_mean.append(temp)\n","\n","        print(\"Training and evaluation is OK.\")\n","\n","        test_auc_round.append(np.mean(test_auc_fold))\n","        test_aupr_round.append(np.mean(test_aupr_fold))\n","\n","    t1 = time.localtime()\n","    time_creat_txt = str(t1.tm_year) + '_' + str(t1.tm_mon) + '_' + str(t1.tm_mday) + '_' + str(t1.tm_hour) + '_' + str(\n","        t1.tm_min)\n","    np.savetxt('test_auc_' + time_creat_txt, test_auc_round)\n","    np.savetxt('test_aupr_' + time_creat_txt, test_aupr_round)\n","\n","    # pos:neg=1:10\n","    tpr = (np.mean(np.array(tpr_mean), axis=0)).tolist()\n","    precision = (np.mean(np.array(precision_mean), axis=0)).tolist()\n","\n","    np.savetxt('fpr.csv', fpr, fmt='%-.4f', delimiter=',')\n","    np.savetxt('tpr.csv', tpr, fmt='%-.4f', delimiter=',')\n","    np.savetxt('recall.csv', recall, fmt='%-.4f', delimiter=',')\n","    np.savetxt('precision.csv', precision, fmt='%-.4f', delimiter=',')\n","\n","\n","if __name__ == \"__main__\":\n","    #args = parse_args()\n","    print(args)\n","\n","    start = time.time()\n","    main(args)\n","    end = time.time()\n","    print(\"Total time:\", end - start)"],"metadata":{"id":"tlugsaCfUouy"},"execution_count":null,"outputs":[]}]}