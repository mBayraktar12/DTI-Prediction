{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DTI2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMzHstN62kEAl/tR7kAU01r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"clObuB6-b3GU","executionInfo":{"status":"ok","timestamp":1653429676984,"user_tz":-180,"elapsed":20228,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"outputId":"39173a5f-0619-4e95-9dd4-a0cc092c3712"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torch.nn.functional as F\n","from torch.nn import MSELoss"],"metadata":{"id":"7Ayq9DSsb9-1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def init_weights(m):\n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_uniform_(m.weight.data,gain=1.0)\n","        nn.init.normal_(m.bias.data, mean=0.0, std=1.0)"],"metadata":{"id":"4OGuOhMwb-Gb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Net(nn.Module):\n","    def __init__(self, args, num_drug, num_disease, num_protein, num_sideeffect,g):\n","        super(Net, self).__init__()\n","        self.args = args \n","        self.criterion = MSELoss(reduction='sum')\n","\n","        # f0(v)\n","        #function for retrieving the initial embedding vector of u.\n","        #torch.Tensor is a multi-dimensional matrix containing elements of a*b\n","        self.drug_embedding = nn.Parameter(torch.Tensor(num_drug, args.d))\n","        self.protein_embedding = nn.Parameter(torch.Tensor(num_protein, args.d))\n","        self.disease_embedding = nn.Parameter(torch.Tensor(num_disease, args.d))\n","        self.sideeffect_embedding = nn.Parameter(torch.Tensor(num_sideeffect, args.d))\n","        \n","        # Wr\n","        # wr and br are edge type nn weights\n","        self.drug_drug_wr = nn.Linear(args.d, args.d)\n","        self.drug_chemical_wr = nn.Linear(args.d, args.d)\n","        self.drug_disease_wr = nn.Linear(args.d, args.d)\n","        self.drug_sideeffect_wr = nn.Linear(args.d, args.d)\n","        self.drug_protein_wr = nn.Linear(args.d, args.d)\n","\n","        self.protein_protein_wr = nn.Linear(args.d, args.d)\n","        self.protein_sequence_wr = nn.Linear(args.d, args.d)\n","        self.protein_disease_wr = nn.Linear(args.d, args.d)\n","        self.protein_drug_wr = nn.Linear(args.d, args.d)\n","\n","        self.disease_drug_wr = nn.Linear(args.d, args.d)\n","        self.disease_protein_wr = nn.Linear(args.d, args.d)\n","\n","        self.sideeffect_drug_wr = nn.Linear(args.d, args.d)\n","\n","        # W1\n","        #weight of nn at the node embedding update step.\n","        self.W1 = nn.Linear(2*args.d, args.d)\n","\n","        # projection G and H\n","        self.drug_disease_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","        self.drug_disease_H = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.drug_drug_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.drug_chemical_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.drug_sideeffect_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","        self.drug_sideeffect_H = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.drug_protein_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","        self.drug_protein_H = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.protein_disease_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","        self.protein_disease_H = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.protein_protein_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.protein_sequence_G = nn.Parameter(torch.Tensor(args.d, args.k))\n","\n","        self.reset_parameters()\n","        self.apply(init_weights)\n","        \n","    def reset_parameters(self):\n","        nn.init.xavier_uniform_(self.drug_disease_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.drug_disease_H, gain=1.0)\n","        nn.init.xavier_uniform_(self.drug_drug_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.drug_chemical_G, gain=1.0)  \n","        nn.init.xavier_uniform_(self.drug_sideeffect_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.drug_sideeffect_H, gain=1.0) \n","        nn.init.xavier_uniform_(self.drug_protein_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.drug_protein_H, gain=1.0)\n","        nn.init.xavier_uniform_(self.protein_disease_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.protein_disease_H, gain=1.0)\n","        nn.init.xavier_uniform_(self.protein_protein_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.protein_sequence_G, gain=1.0)\n","        nn.init.xavier_uniform_(self.drug_embedding, gain=1.0)\n","        nn.init.xavier_uniform_(self.protein_embedding, gain=1.0)\n","        nn.init.xavier_uniform_(self.disease_embedding, gain=1.0)\n","        nn.init.xavier_uniform_(self.sideeffect_embedding, gain=1.0)\n","    \n","    def forward(self, drug_drug_normalize, drug_chemical_normalize, drug_disease_normalize, drug_sideeffect_normalize, protein_protein_normalize, protein_sequence_normalize, protein_disease_normalize, \n","    disease_drug_normalize, disease_protein_normalize, sideeffect_drug_normalize, drug_protein_normalize, protein_drug_normalize, drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, protein_sequence, protein_disease, \n","    drug_protein, drug_protein_mask):\n","        # passing 1 times (can be easily extended to multiple passes)\n","        #F.normalize performs Lp normalization of inputs\n","        drug_vector1 = F.normalize(torch.sigmoid(self.W1(torch.cat([\n","            torch.matmul(drug_drug_normalize, self.drug_drug_wr(self.drug_embedding)) + \\\n","            torch.matmul(drug_chemical_normalize, self.drug_chemical_wr(self.drug_embedding)) + \\\n","            torch.matmul(drug_disease_normalize, self.drug_disease_wr(self.disease_embedding)) + \\\n","            torch.matmul(drug_sideeffect_normalize, self.drug_sideeffect_wr(self.sideeffect_embedding)) + \\\n","            torch.matmul(drug_protein_normalize, self.drug_protein_wr(self.protein_embedding)), \n","            self.drug_embedding\n","        ], dim=1))))\n","\n","        protein_vector1 = F.normalize(torch.sigmoid(self.W1(torch.cat([\n","            torch.matmul(protein_protein_normalize, self.protein_protein_wr(self.protein_embedding)) + \\\n","            torch.matmul(protein_sequence_normalize, self.protein_sequence_wr(self.protein_embedding)) + \\\n","            torch.matmul(protein_disease_normalize, self.protein_disease_wr(self.disease_embedding)) + \\\n","            torch.matmul(protein_drug_normalize, self.protein_drug_wr(self.drug_embedding)), \n","            self.protein_embedding\n","        ], dim=1))))\n","\n","        disease_vector1 = F.normalize(torch.sigmoid(self.W1(torch.cat([\n","            torch.matmul(disease_drug_normalize, self.disease_drug_wr(self.drug_embedding)) + \\\n","            torch.matmul(disease_protein_normalize, self.disease_protein_wr(self.protein_embedding)),\n","            self.disease_embedding\n","        ], dim=1))))\n","\n","        sideeffect_vector1 = F.normalize(torch.sigmoid(self.W1(torch.cat([\n","            torch.matmul(sideeffect_drug_normalize, self.sideeffect_drug_wr(self.drug_embedding)),\n","            self.sideeffect_embedding\n","        ], dim=1))))\n","        # print(protein_vector1, disease_vector1, drug_vector1, sideeffect_vector1)\n","        # reconstructing networks\n","\n","        #torch.linalg.multi_dot multiplies multiple matrices.\n","        drug_drug_reconstruct = torch.linalg.multi_dot([drug_vector1, self.drug_drug_G, self.drug_drug_G.T, drug_vector1.T])\n","        drug_drug_reconstruct_loss = self.criterion(drug_drug_reconstruct, drug_drug)\n","        \n","        drug_chemical_reconstruct = torch.linalg.multi_dot([drug_vector1, self.drug_chemical_G, self.drug_chemical_G.T, drug_vector1.T])\n","        drug_chemical_reconstruct_loss = self.criterion(drug_chemical_reconstruct, drug_chemical)\n","\n","        drug_disease_reconstruct = torch.linalg.multi_dot([drug_vector1, self.drug_disease_G, self.drug_disease_H.T, disease_vector1.T])\n","        drug_disease_reconstruct_loss = self.criterion(drug_disease_reconstruct, drug_disease)\n","\n","        drug_sideeffect_reconstruct = torch.linalg.multi_dot([drug_vector1, self.drug_sideeffect_G, self.drug_sideeffect_H.T, sideeffect_vector1.T])\n","        drug_sideeffect_reconstruct_loss = self.criterion(drug_sideeffect_reconstruct, drug_sideeffect)\n","\n","        protein_protein_reconstruct = torch.linalg.multi_dot([protein_vector1, self.protein_protein_G, self.protein_protein_G.T, protein_vector1.T])\n","        protein_protein_reconstruct_loss = self.criterion(protein_protein_reconstruct, protein_protein)\n","\n","        protein_sequence_reconstruct = torch.linalg.multi_dot([protein_vector1, self.protein_sequence_G, self.protein_sequence_G.T, protein_vector1.T])\n","        protein_sequence_reconstruct_loss = self.criterion(protein_sequence_reconstruct, protein_sequence)\n","        \n","        protein_disease_reconstruct = torch.linalg.multi_dot([protein_vector1, self.protein_disease_G, self.protein_disease_H.T, disease_vector1.T])\n","        protein_disease_reconstruct_loss  = self.criterion(protein_disease_reconstruct, protein_disease)\n","\n","        drug_protein_reconstruct = torch.linalg.multi_dot([drug_vector1, self.drug_protein_G, self.drug_protein_H.T, protein_vector1.T])\n","        tmp = torch.mul(drug_protein_mask, (drug_protein_reconstruct - drug_protein))\n","        drug_protein_reconstruct_loss = torch.sum(tmp.pow(2))\n","            \n","        other_loss = drug_drug_reconstruct_loss + drug_chemical_reconstruct_loss + drug_disease_reconstruct_loss + drug_sideeffect_reconstruct_loss + protein_protein_reconstruct_loss + protein_sequence_reconstruct_loss + protein_disease_reconstruct_loss       \n","\n","    \n","        total_loss = drug_protein_reconstruct_loss + 1.0 * (other_loss)\n","        \n","        return total_loss, drug_protein_reconstruct_loss, drug_protein_reconstruct.detach().cpu().numpy()"],"metadata":{"id":"y8xAfHmob-Ig"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np \n","import torch, os, argparse, random\n","from sklearn.metrics import roc_auc_score, average_precision_score\n","from sklearn.model_selection import train_test_split, StratifiedKFold"],"metadata":{"id":"zoDUPBMJb-K7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def set_seed(args):\n","    random.seed(args.seed)\n","    np.random.seed(args.seed)\n","    torch.manual_seed(args.seed)\n","    torch.cuda.manual_seed_all(args.seed)"],"metadata":{"id":"zY5lUqGXcHf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import easydict\n","\n","def get_args():\n","  args = easydict.EasyDict({\n","     \"seed\": 26, #random seed for init.\n","     \"d\": 1024, #the embedding dim.\n","     \"n\":1.0, #global gradient norm\n","     \"k\":512, #the dim. of reprojection matrices k.\n","     \"t\":\"o\", #the dti matrix for testing, o -> mat_drug_protein.txt.\n","     \"r\":\"ten\", #positive-negative ratio.\n","     \"lr\":1e-3, #learning rate\n","     \"weight_decay\":60, #weight decay of the optimizer\n","     \"num_steps\":100, #no. of forward propg.\n","     \"device\":\"cuda\", # device type.\n","     \"n_folds\":3, #number of folds for cross vld.\n","     \"round\":1, # number of rounds of sampling\n","     \"test_size\":0.05 # portion of vld. data.\n","})\n","  return args"],"metadata":{"id":"Hj28vp5DcHk9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def row_normalize(a_matrix, substract_self_loop):\n","    if substract_self_loop == True:\n","        np.fill_diagonal(a_matrix,0)\n","    a_matrix = a_matrix.astype(float)\n","    row_sums = a_matrix.sum(axis=1)+1e-12\n","    new_matrix = a_matrix / row_sums[:, np.newaxis]\n","    new_matrix[np.isnan(new_matrix) | np.isinf(new_matrix)] = 0.0\n","    return torch.Tensor(new_matrix)"],"metadata":{"id":"nXpNa-9ecLCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install dgl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eyap-MdCcLHC","executionInfo":{"status":"ok","timestamp":1653429684635,"user_tz":-180,"elapsed":4236,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"outputId":"95acedf0-6f7c-4299-b9b5-defd9cc4865d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting dgl\n","  Downloading dgl-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 13.9 MB/s \n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.21.6)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.6.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2022.5.18.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n","Installing collected packages: dgl\n","Successfully installed dgl-0.6.1\n"]}]},{"cell_type":"code","source":["import dgl"],"metadata":{"id":"B-1dhDFDmw8K","executionInfo":{"status":"ok","timestamp":1653429685191,"user_tz":-180,"elapsed":572,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5df19e4d-6fa4-46fe-e932-4a082e177695"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"output_type":"stream","name":"stderr","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Using backend: pytorch\n"]}]},{"cell_type":"code","source":["def train_and_evaluate(args, DTItrain, DTIvalid, DTItest, verbose=True):\n","    set_seed(args)\n","    drug_protein = np.zeros((num_drug,num_protein))\n","    mask = np.zeros((num_drug,num_protein))\n","    for ele in DTItrain:\n","        drug_protein[ele[0],ele[1]] = ele[2]\n","        mask[ele[0],ele[1]] = 1\n","    protein_drug = drug_protein.T\n","\n","    drug_protein_normalize = row_normalize(drug_protein,False).to(device)\n","    protein_drug_normalize = row_normalize(protein_drug,False).to(device)\n","    drug_protein = torch.Tensor(drug_protein).to(device)\n","    \n","    mask = torch.Tensor(mask).to(device)\n","    model = Net(args, num_drug, num_disease, num_protein, num_sideeffect,g)\n","    model.to(device)\n","    no_decay = [\"bias\"]\n","    optimizer_grouped_parameters = [\n","        {\n","            \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n","            \"weight_decay\": args.weight_decay,\n","        },\n","        {\"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n","    ]\n","\n","    optimizer = torch.optim.Adam(optimizer_grouped_parameters, lr=args.lr, weight_decay=args.weight_decay)\n","    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'max', factor=0.8, patience=2)\n","\n","    ground_truth_train = [ele[2] for ele in DTItrain]\n","    ground_truth_valid = [ele[2] for ele in DTIvalid]\n","    ground_truth_test = [ele[2] for ele in DTItest]\n","\n","\n","    best_valid_aupr = 0\n","    best_valid_auc = 0\n","    test_aupr = 0\n","    test_auc = 0\n","    for i in range(args.num_steps):\n","        model.train()\n","        model.zero_grad()\n","        tloss, dtiloss, results = model(drug_drug_normalize, drug_chemical_normalize, drug_disease_normalize, \n","                                        drug_sideeffect_normalize, protein_protein_normalize, protein_sequence_normalize, \n","                                        protein_disease_normalize, disease_drug_normalize, disease_protein_normalize, \n","                                        sideeffect_drug_normalize, drug_protein_normalize, protein_drug_normalize, \n","                                        drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, \n","                                        protein_sequence, protein_disease, drug_protein, mask)\n","        # print(results)\n","        tloss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), args.n)\n","        optimizer.step()\n","        if i % 25 == 0 and verbose == True:\n","            print('step', i, 'total and dti loss', tloss.item(), dtiloss.item())\n","            model.eval()\n","            pred_list_valid = [results[ele[0],ele[1]] for ele in DTIvalid]\n","            valid_auc = roc_auc_score(ground_truth_valid, pred_list_valid)\n","            valid_aupr = average_precision_score(ground_truth_valid, pred_list_valid)\n","\n","            pred_list_train = [results[ele[0],ele[1]] for ele in DTItrain]\n","            train_auc = roc_auc_score(ground_truth_train, pred_list_train)\n","            train_aupr = average_precision_score(ground_truth_train, pred_list_train)\n","            scheduler.step(train_aupr)\n","            if valid_aupr >= best_valid_aupr:\n","                best_valid_aupr = valid_aupr\n","                best_valid_auc = valid_auc\n","                pred_list_test = [results[ele[0],ele[1]] for ele in DTItest]\n","                test_auc = roc_auc_score(ground_truth_test, pred_list_test)\n","                test_aupr = average_precision_score(ground_truth_test, pred_list_test)\n","            print ('train auc aupr', train_auc, train_aupr, 'valid auc aupr,', valid_auc, valid_aupr, 'test auc aupr', test_auc, test_aupr)\n","        \n","    return best_valid_auc, best_valid_aupr, test_auc, test_aupr\n","\n","if __name__ == '__main__':\n","    args = get_args()\n","    set_seed(args)\n","    device = torch.device(args.device)\n","    network_path = '/content/drive/MyDrive/Colab Notebooks/data/'\n","    print('loading networks ...')\n","    drug_drug = np.loadtxt(network_path+'mat_drug_drug.txt')\n","    true_drug = 708 # First [0:708] are drugs, the rest are compounds retrieved from ZINC15 database\n","    drug_chemical = np.loadtxt(network_path+'Similarity_Matrix_Drugs.txt')\n","    drug_chemical=drug_chemical[:true_drug,:true_drug]\n","    drug_disease = np.loadtxt(network_path+'mat_drug_disease.txt')\n","    drug_sideeffect = np.loadtxt(network_path+'mat_drug_se.txt')\n","    disease_drug = drug_disease.T\n","    sideeffect_drug = drug_sideeffect.T\n","\n","    protein_protein = np.loadtxt(network_path+'mat_protein_protein.txt')\n","    protein_sequence = np.loadtxt(network_path+'Similarity_Matrix_Proteins.txt')\n","    protein_disease = np.loadtxt(network_path+'mat_protein_disease.txt')\n","    disease_protein = protein_disease.T\n","\n","    def ConstructGraph(drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, protein_sequence,\n","                   protein_disease):\n","      num_drug = len(drug_drug)\n","      num_protein = len(protein_protein)\n","      num_disease = len(drug_disease.T)\n","      num_sideeffect = len(drug_sideeffect.T)\n","\n","      list_drug = []\n","      for i in range(num_drug):\n","          list_drug.append((i, i))\n","\n","      list_protein = []\n","      for i in range(num_protein):\n","          list_protein.append((i, i))\n","\n","      list_disease = []\n","      for i in range(num_disease):\n","          list_disease.append((i, i))\n","\n","      list_sideeffect = []\n","      for i in range(num_sideeffect):\n","          list_sideeffect.append((i, i))\n","\n","      list_DDI = []\n","      for row in range(num_drug):\n","          for col in range(num_drug):\n","              if drug_drug[row, col] > 0:\n","                  list_DDI.append((row, col))\n","\n","      list_PPI = []\n","      for row in range(num_protein):\n","          for col in range(num_protein):\n","              if protein_protein[row, col] > 0:\n","                  list_PPI.append((row, col))\n","\n","      list_drug_sideeffect = []\n","      list_sideeffect_drug = []\n","      for row in range(num_drug):\n","          for col in range(num_sideeffect):\n","              if drug_sideeffect[row, col] > 0:\n","                  list_drug_sideeffect.append((row, col))\n","                  list_sideeffect_drug.append((col, row))\n","\n","      list_drug_disease = []\n","      list_disease_drug = []\n","      for row in range(num_drug):\n","          for col in range(num_disease):\n","              if drug_disease[row, col] > 0:\n","                  list_drug_disease.append((row, col))\n","                  list_disease_drug.append((col, row))\n","\n","      list_protein_disease = []\n","      list_disease_protein = []\n","      for row in range(num_protein):\n","          for col in range(num_disease):\n","              if protein_disease[row, col] > 0:\n","                  list_protein_disease.append((row, col))\n","                  list_disease_protein.append((col, row))\n","\n","      g_HIN = dgl.heterograph({('disease', 'disease_disease virtual', 'disease'): list_disease,\n","                             ('drug', 'drug_drug virtual', 'drug'): list_drug,\n","                             ('protein', 'protein_protein virtual', 'protein'): list_protein,\n","                             ('sideeffect', 'sideeffect_sideeffect virtual', 'sideeffect'): list_sideeffect,\n","                             ('drug', 'drug_drug interaction', 'drug'): list_DDI, \\\n","                             ('protein', 'protein_protein interaction', 'protein'): list_PPI, \\\n","                             ('drug', 'drug_sideeffect association', 'sideeffect'): list_drug_sideeffect, \\\n","                             ('sideeffect', 'sideeffect_drug association', 'drug'): list_sideeffect_drug, \\\n","                             ('drug', 'drug_disease association', 'disease'): list_drug_disease, \\\n","                             ('disease', 'disease_drug association', 'drug'): list_disease_drug, \\\n","                             ('protein', 'protein_disease association', 'disease'): list_protein_disease, \\\n","                             ('disease', 'disease_protein association', 'protein'): list_disease_protein})\n","\n","      g = g_HIN.edge_type_subgraph(['drug_drug interaction', 'protein_protein interaction',\n","                                  'drug_sideeffect association', 'sideeffect_drug association',\n","                                  'drug_disease association', 'disease_drug association',\n","                                  'protein_disease association', 'disease_protein association'\n","                                  ])\n","\n","      return g\n","      \n","    \n","    print('normalize network for mean pooling aggregation')\n","    drug_drug_normalize = row_normalize(drug_drug,True).to(device)\n","    drug_chemical_normalize = row_normalize(drug_chemical,True).to(device)\n","    drug_disease_normalize = row_normalize(drug_disease,False).to(device)\n","    drug_sideeffect_normalize = row_normalize(drug_sideeffect,False).to(device)\n","\n","    protein_protein_normalize = row_normalize(protein_protein,True).to(device)\n","    protein_sequence_normalize = row_normalize(protein_sequence,True).to(device)\n","    protein_disease_normalize = row_normalize(protein_disease,False).to(device)\n","\n","    disease_drug_normalize = row_normalize(disease_drug,False).to(device)\n","    disease_protein_normalize = row_normalize(disease_protein,False).to(device)\n","    sideeffect_drug_normalize = row_normalize(sideeffect_drug,False).to(device)\n","\n","    \n","\n","    #define computation graph\n","\n","    g = ConstructGraph(drug_drug, drug_chemical, drug_disease, drug_sideeffect, protein_protein, protein_sequence,\n","                       protein_disease)\n","\n","    num_drug = len(drug_drug_normalize)\n","    num_protein = len(protein_protein_normalize)\n","    num_disease = len(disease_protein_normalize)\n","    num_sideeffect = len(sideeffect_drug_normalize)\n","\n","    drug_drug = torch.Tensor(drug_drug).to(device)\n","    drug_chemical = torch.Tensor(drug_chemical).to(device)\n","    drug_disease = torch.Tensor(drug_disease).to(device)\n","    drug_sideeffect = torch.Tensor(drug_sideeffect).to(device)\n","    protein_protein = torch.Tensor(protein_protein).to(device)\n","    protein_sequence = torch.Tensor(protein_sequence).to(device)\n","    protein_disease = torch.Tensor(protein_disease).to(device)\n","\n","    # prepare drug_protein and mask\n","    test_auc_round = []\n","    test_aupr_round = []\n","    val_auc_round = []\n","    val_aupr_round = []\n","\n","\n","    if args.t == 'o':\n","        dti_o = np.loadtxt(network_path+'mat_drug_protein.txt')\n","    else:\n","        dti_o = np.loadtxt(network_path+'mat_drug_protein_'+args.t+'.txt')\n","\n","    whole_positive_index = []\n","    whole_negative_index = []\n","    for i in range(np.shape(dti_o)[0]):\n","        for j in range(np.shape(dti_o)[1]):\n","            if int(dti_o[i][j]) == 1:\n","                whole_positive_index.append([i,j])\n","            elif int(dti_o[i][j]) == 0:\n","                whole_negative_index.append([i,j])\n","\n","    for r in range(args.round):\n","        print ('sample round',r+1)\n","        if args.r == 'ten':\n","            negative_sample_index = np.random.choice(np.arange(len(whole_negative_index)),size=10*len(whole_positive_index),replace=False)\n","        elif args.r == 'all':\n","            negative_sample_index = np.arange(len(whole_negative_index))\n","        else:\n","            print ('wrong positive negative ratio')\n","            break\n","\n","        data_set = np.zeros((len(negative_sample_index)+len(whole_positive_index),3),dtype=int)\n","        count = 0\n","        for i in whole_positive_index:\n","            data_set[count][0] = i[0]\n","            data_set[count][1] = i[1]\n","            data_set[count][2] = 1\n","            count += 1\n","        for i in negative_sample_index:\n","            data_set[count][0] = whole_negative_index[i][0]\n","            data_set[count][1] = whole_negative_index[i][1]\n","            data_set[count][2] = 0\n","            count += 1\n","\n","\n","\n","        if args.t == 'unique':\n","            whole_positive_index_test = []\n","            whole_negative_index_test = []\n","            for i in range(np.shape(dti_o)[0]):\n","                for j in range(np.shape(dti_o)[1]):\n","                    if int(dti_o[i][j]) == 3:\n","                        whole_positive_index_test.append([i,j])\n","                    elif int(dti_o[i][j]) == 2:\n","                        whole_negative_index_test.append([i,j])\n","\n","            if args.r == 'ten':\n","                negative_sample_index_test = np.random.choice(np.arange(len(whole_negative_index_test)),size=10*len(whole_positive_index_test),replace=False)\n","            elif args.r == 'all':\n","                negative_sample_index_test = np.arange(len(whole_negative_index_test))\n","            else:\n","                print ('wrong positive negative ratio')\n","                break\n","            data_set_test = np.zeros((len(negative_sample_index_test)+len(whole_positive_index_test),3),dtype=int)\n","            count = 0\n","            for i in whole_positive_index_test:\n","                data_set_test[count][0] = i[0]\n","                data_set_test[count][1] = i[1]\n","                data_set_test[count][2] = 1\n","                count += 1\n","            for i in negative_sample_index_test:\n","                data_set_test[count][0] = whole_negative_index_test[i][0]\n","                data_set_test[count][1] = whole_negative_index_test[i][1]\n","                data_set_test[count][2] = 0\n","                count += 1\n","\n","            DTItrain = data_set\n","            DTItest = data_set_test\n","            rs = np.random.randint(0,1000,1)[0]\n","            DTItrain, DTIvalid =  train_test_split(DTItrain, test_size=args.test_size, random_state=rs)\n","            v_auc, v_aupr, t_auc, t_aupr = train_and_evaluate(DTItrain=DTItrain, DTIvalid=DTIvalid, DTItest=DTItest)\n","\n","            test_auc_round.append(t_auc)\n","            test_aupr_round.append(t_aupr)\n","            np.savetxt('/content/drive/MyDrive/Colab Notebooks/data/test_auc.csv', test_auc_round,fmt=\"%.4f\")\n","            np.savetxt('/content/drive/MyDrive/Colab Notebooks/data/test_aupr.csv', test_aupr_round,fmt=\"%.4f\")\n","\n","        else:\n","            val_auc_fold = []\n","            val_aupr_fold = []\n","            test_auc_fold = []\n","            test_aupr_fold = []\n","            rs = np.random.randint(0,1000,1)[0]\n","            skf = StratifiedKFold(n_splits=args.n_folds, shuffle=True, random_state=rs)\n","\n","            for train_index, test_index in skf.split(np.arange(len(data_set)), data_set[:,2]):\n","                DTItrain, DTItest = data_set[train_index], data_set[test_index]\n","                DTItrain, DTIvalid =  train_test_split(DTItrain, test_size=args.test_size, random_state=rs)\n","\n","                v_auc, v_aupr, t_auc, t_aupr = train_and_evaluate(args=args, DTItrain=DTItrain, DTIvalid=DTIvalid, DTItest=DTItest)\n","                val_auc_fold.append(v_auc)\n","                val_aupr_fold.append(v_aupr)\n","                test_auc_fold.append(t_auc)\n","                test_aupr_fold.append(t_aupr)\n","                # break\n","            val_auc_round.append(np.mean(val_auc_fold))\n","            val_aupr_round.append(np.mean(val_aupr_fold))\n","            test_auc_round.append(np.mean(test_auc_fold))\n","            test_aupr_round.append(np.mean(test_aupr_fold))\n","            np.savetxt('/content/drive/MyDrive/Colab Notebooks/data/val_auc.csv', val_auc_round,fmt=\"%.4f\")\n","            np.savetxt('/content/drive/MyDrive/Colab Notebooks/data/val_aupr.csv', val_aupr_round,fmt=\"%.4f\")\n","            np.savetxt('/content/drive/MyDrive/Colab Notebooks/data/test_auc.csv', test_auc_round,fmt=\"%.4f\")\n","            np.savetxt('/content/drive/MyDrive/Colab Notebooks/data/test_aupr.csv', test_aupr_round,fmt=\"%.4f\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"J_Enwt00ervh","executionInfo":{"status":"ok","timestamp":1653431552729,"user_tz":-180,"elapsed":84847,"user":{"displayName":"Mert Bayraktar","userId":"05383922882662101824"}},"outputId":"0c38c1af-6ad6-4f0e-dcef-f8b9e8eead61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["loading networks ...\n","normalize network for mean pooling aggregation\n","sample round 1\n","step 0 total and dti loss 317056128.0 1287.08984375\n","train auc aupr 0.1712802815882898 0.05416426530429627 valid auc aupr, 0.31729571737196594 0.059582199874294216 test auc aupr 0.28361399042545166 0.05884562554454195\n","step 25 total and dti loss 339180160.0 1229.71484375\n","train auc aupr 0.4598926049439397 0.0789560914096818 valid auc aupr, 0.5029355699580633 0.09016132530164629 test auc aupr 0.5085235141074909 0.08833614041580662\n","step 50 total and dti loss 346201184.0 1221.998291015625\n","train auc aupr 0.7453475540128518 0.15271883148173226 valid auc aupr, 0.6947515567416445 0.13953414723406193 test auc aupr 0.6959108598353293 0.13627064475737677\n","step 75 total and dti loss 347450144.0 1221.28271484375\n","train auc aupr 0.4825095395937285 0.08328413367571721 valid auc aupr, 0.4540856525606811 0.07694935966394334 test auc aupr 0.6959108598353293 0.13627064475737677\n","step 0 total and dti loss 317047264.0 1286.922119140625\n","train auc aupr 0.18223888252635684 0.05491110834019842 valid auc aupr, 0.2876096073198627 0.05747514960528203 test auc aupr 0.2730666543354402 0.05794885323571025\n","step 25 total and dti loss 339180160.0 1229.703369140625\n","train auc aupr 0.48516074783015234 0.08274558819806142 valid auc aupr, 0.5191002668699962 0.0848828723640061 test auc aupr 0.5002156342103918 0.08715934972829638\n","step 50 total and dti loss 346201152.0 1221.99853515625\n","train auc aupr 0.7500589108802662 0.15666435367029624 valid auc aupr, 0.7013470580759944 0.13468008301147114 test auc aupr 0.6963107323044871 0.13905040333878765\n","step 75 total and dti loss 347450144.0 1221.282958984375\n","train auc aupr 0.45905295252317835 0.07924814512150856 valid auc aupr, 0.44381751175498796 0.07389107056310146 test auc aupr 0.6963107323044871 0.13905040333878765\n","step 0 total and dti loss 317052704.0 1287.078369140625\n","train auc aupr 0.17217368198887703 0.05424085890344637 valid auc aupr, 0.2840767568941416 0.057296399497704625 test auc aupr 0.28587510739119115 0.05895834664030721\n","step 25 total and dti loss 339180160.0 1229.7161865234375\n","train auc aupr 0.4550383013216689 0.07831190000730646 valid auc aupr, 0.4966831871902402 0.08140407192922858 test auc aupr 0.5107077231607204 0.08878697828545339\n","step 50 total and dti loss 346201184.0 1221.998291015625\n","train auc aupr 0.7465601461084007 0.15482141321075973 valid auc aupr, 0.697255051467785 0.12638486060543713 test auc aupr 0.7023389983961295 0.1384650037660027\n","step 75 total and dti loss 347450144.0 1221.28271484375\n","train auc aupr 0.4867436561071058 0.08411347056065165 valid auc aupr, 0.46594230524844327 0.07583123822731408 test auc aupr 0.7023389983961295 0.1384650037660027\n"]}]},{"cell_type":"code","source":[""],"metadata":{"id":"w6QQw3SvcXFL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[""],"metadata":{"id":"Jsh8wuT-ctPd"},"execution_count":null,"outputs":[]}]}